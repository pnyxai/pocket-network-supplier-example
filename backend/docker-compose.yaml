services:
  vllm-relayminer:
    container_name: vllm-relayminer
    image: vllm/vllm-openai:v0.15.0
    volumes:
      - ${MODELS_PATH}:/root/.cache/huggingface/hub/
    environment:
      - HF_TOKEN=${HF_TOKEN}
    entrypoint: ["python3",
                  "-m",
                  "vllm.entrypoints.openai.api_server",
                  "--model",
                  "${MODEL_NAME}",
                  "--dtype",
                  "${DTYPE}",
                  "--gpu-memory-utilization",
                  "${GPU_MEMORY_UTILIZATION}",
                  "--max-model-len",
                  "${MAX_MODEL_LEN}",
                  "--trust-remote-code",
                  ]
    ports:
      - "8800:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    networks:
      - pokt-relayminer-ai

  poncho-sidecar:
      container_name: poncho-sidecar
      image: ghcr.io/pnyxai/pokt-ml-sidecar:latest
      deploy:
          replicas: 1
      environment:
          CONFIG_PATH: /config/config.yaml
      volumes:
          - $PONCHO_CONFIG_FILE:/config/config.yaml
      ports:
          - "8000:8080"
      networks:
        - pokt-relayminer-ai

networks:
  pokt-relayminer-ai:
    name: pokt-relayminer-ai
    driver: bridge
    external: true